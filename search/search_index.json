{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"MLArray","text":"<p>tl;dr: Working with large medical or scientific images for machine learning? -&gt; Use MLArray.</p> <p>MLArray is a purpose-built file format for N-dimensional medical and scientific array data in machine learning workflows. It replaces the usual patchwork of source formats and late-stage conversions to NumPy/Zarr/Blosc2 by layering standardized metadata on top of a Blosc2-backed storage layout, so the same files work reliably across training, analysis, and visualization tools (including Napari and MITK).</p>"},{"location":"#installation","title":"Installation","text":"<p>You can install mlarray via pip: <pre><code>pip install mlarray\n</code></pre></p> <p>To enable the <code>mlarray_convert</code> CLI command, install MLArray with the necessary extra dependencies: <pre><code>pip install mlarray[all]\n</code></pre></p>"},{"location":"#documentaion","title":"Documentaion","text":"<p>See the documentation for the API reference, the metadata schema, usage examples or CLI usage.</p>"},{"location":"#usage","title":"Usage","text":"<p>Below are common usage patterns for loading, saving, and working with metadata.</p>"},{"location":"#default-usage","title":"Default usage","text":"<pre><code>import numpy as np\nfrom mlarray import MLArray\n\narray = np.random.random((128, 256, 256))\nimage = MLArray(array)  # Create MLArray image\nimage.save(\"sample.mla\")\n\nimage = MLArray(\"sample.mla\")  # Loads image\n</code></pre>"},{"location":"#memory-mapped-usage","title":"Memory-mapped usage","text":"<pre><code>from mlarray import MLArray\nimport numpy as np\n\n# read-only, partial access (default)\nimage = MLArray.open(\"sample.mla\", mmap_mode='r')  \ncrop = image[10:20, 50:60]  # Read crop\n\n# read/write, partial access\nimage = MLArray.open(\"sample.mla\", mmap_mode='r+')  \nimage[10:20, 50:60] *= 5  # Modify crop in memory and disk\n\n# read/write, partial access, create/overwrite\narray = np.random.random((128, 256, 256))\nimage = MLArray.create(\"sample.mla\", shape=array.shape, dtype=array.dtype, mmap_mode='w+')\nimage[...] = array  # Modify image in memory and disk\n</code></pre>"},{"location":"#metadata-inspection-and-manipulation","title":"Metadata inspection and manipulation","text":"<pre><code>import numpy as np\nfrom mlarray import MLArray\n\narray = np.random.random((64, 128, 128))\nimage = MLArray(\n    array,\n    spacing=(1.0, 1.0, 1.5),\n    origin=(10.0, 10.0, 30.0),\n    direction=[[1, 0, 0], [0, 1, 0], [0, 0, 1]],\n    meta={\"patient_id\": \"123\", \"modality\": \"CT\"},  # Any metadata from the original image source (for example raw DICOM metadata)\n)\n\nprint(image.spacing)  # [1.0, 1.0, 1.5]\nprint(image.origin)  # [10.0, 10.0, 30.0]\nprint(image.meta.source)  # {\"patient_id\": \"123\", \"modality\": \"CT\"}\n\nimage.spacing[1] = 5.3\nimage.meta.source[\"study_id\"] = \"study-001\"\nimage.save(\"with-metadata.mla\")\n\n# Open memory-mapped\nimage = MLArray.open(\"with-metadata.mla\", mmap_mode='r+')  \nimage.meta.source[\"study_id\"] = \"new-study\"  # Modify metadata\nimage.close()  # Close and save metadata, only necessary to save modified metadata\n</code></pre>"},{"location":"#copy-metadata-with-overrides","title":"Copy metadata with overrides","text":"<pre><code>import numpy as np\nfrom mlarray import MLArray\n\nbase = MLArray(\"sample.mla\")\narray = np.random.random(base.shape)\n\nimage = MLArray(\n    array,\n    spacing=(0.8, 0.8, 1.0),\n    copy=base,  # Copies all non-explicitly set arguments from base\n)\n\nimage.save(\"copied-metadata.mla\")\n</code></pre>"},{"location":"#standardized-metadata-usage","title":"Standardized metadata usage","text":"<pre><code>import numpy as np\nfrom mlarray import MLArray, Meta\n\narray = np.random.random((64, 128, 128))\nimage = MLArray(\n    array,\n    meta=Meta(source={\"patient_id\": \"123\", \"modality\": \"CT\"}, is_seg=True),  # Add metadata in a pre-defined format\n)\n\nprint(image.meta.source)  # {\"patient_id\": \"123\", \"modality\": \"CT\"}\nprint(image.meta.is_seg)  # True\n\nimage.meta.source[\"study_id\"] = \"study-001\"\nimage.meta.is_seg = False\nimage.save(\"with-metadata.mla\")\n</code></pre>"},{"location":"#patch-size-variants","title":"Patch size variants","text":"<p>Default patch size (192): <pre><code>from mlarray import MLArray\n\nimage = MLArray(\"sample.mla\")  # Existing file\nimage.save(\"default-patch.mla\")  # Keeps existing layout metadata\n\nloaded = MLArray(\"sample.mla\")\nimage = MLArray(loaded.to_numpy(), patch_size='default')\nimage.save(\"default-patch-relayout.mla\")  # Uses constructor patch_size='default' (192)\n</code></pre></p> <p>Custom isotropic patch size (512): <pre><code>from mlarray import MLArray\n\nloaded = MLArray(\"sample.mla\")\nimage = MLArray(loaded.to_numpy(), patch_size=512)\nimage.save(\"patch-512.mla\")\n</code></pre></p> <p>Custom non-isotropic patch size: <pre><code>from mlarray import MLArray\n\nloaded = MLArray(\"sample.mla\")\nimage = MLArray(loaded.to_numpy(), patch_size=(128, 192, 256))\nimage.save(\"patch-non-iso.mla\")\n</code></pre></p> <p>Manual chunk/block size: <pre><code>from mlarray import MLArray\n\nloaded = MLArray(\"sample.mla\")\nimage = MLArray(\n    loaded.to_numpy(),\n    patch_size=None,\n    chunk_size=(1, 128, 128),\n    block_size=(1, 32, 32),\n)\nimage.save(\"manual-chunk-block.mla\")\n</code></pre></p> <p>Let Blosc2 itself configure chunk/block size: <pre><code>from mlarray import MLArray\n\nloaded = MLArray(\"sample.mla\")\nimage = MLArray(loaded.to_numpy(), patch_size=None)\n# If patch_size, chunk_size and block_size are all None, Blosc2 will auto-configure chunk and block size\nimage.save(\"blosc2-auto.mla\")\n</code></pre></p>"},{"location":"#cli","title":"CLI","text":""},{"location":"#mlarray_header","title":"mlarray_header","text":"<p>Print the metadata header from a <code>.mla</code> file.</p> <pre><code>mlarray_header sample.mla\n</code></pre>"},{"location":"#mlarray_convert","title":"mlarray_convert","text":"<p>Convert a NIfTI or NRRD file to MLArray and copy metadata.</p> <pre><code>mlarray_convert sample.nii.gz output.mla\n</code></pre>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please open a pull request with clear changes and add tests when appropriate.</p>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<p>This repository is developed and maintained by the Applied Computer Vision Lab (ACVL) of Helmholtz Imaging and the Division of Medical Image Computing at DKFZ.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#mlarray-module","title":"MLArray Module","text":""},{"location":"api/#mlarray.mlarray.MLArray","title":"mlarray.mlarray.MLArray","text":"<pre><code>MLArray(array: Optional[Union[ndarray, str, Path]] = None, spacing: Optional[Union[List, Tuple, ndarray]] = None, origin: Optional[Union[List, Tuple, ndarray]] = None, direction: Optional[Union[List, Tuple, ndarray]] = None, affine: Optional[Union[List, Tuple, ndarray]] = None, meta: Optional[Union[Dict, Meta]] = None, axis_labels: Optional[List[Union[str, AxisLabel]]] = None, copy: Optional[MLArray] = None, patch_size: Optional[Union[int, List, Tuple]] = 'default', chunk_size: Optional[Union[int, List, Tuple]] = None, block_size: Optional[Union[int, List, Tuple]] = None, cparams: Optional[Union[Dict, CParams]] = None, dparams: Optional[Union[Dict, DParams]] = None, compressed: bool = True)\n</code></pre> <p>Initializes a MLArray instance.</p> <p>The MLArray file format (\".mla\") is a Blosc2-compressed container with standardized metadata support for N-dimensional medical images.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>Optional[Union[ndarray, str, Path]]</code> <p>Input data or file path. Use a numpy ndarray for in-memory arrays, or a string/Path to load a \".mla\" file. If None, an empty MLArray instance is created.</p> <code>None</code> <code>spacing</code> <code>Optional[Union[List, Tuple, ndarray]]</code> <p>Spacing per spatial axis. Provide a list/tuple/ndarray with length equal to the number of spatial dimensions (e.g., [sx, sy, sz]).</p> <code>None</code> <code>origin</code> <code>Optional[Union[List, Tuple, ndarray]]</code> <p>Origin per axis. Provide a list/tuple/ndarray with length equal to the number of spatial dimensions.</p> <code>None</code> <code>direction</code> <code>Optional[Union[List, Tuple, ndarray]]</code> <p>Direction cosine matrix. Provide a 2D list/tuple/ndarray with shape (ndims, ndims) for spatial dimensions.</p> <code>None</code> <code>affine</code> <code>Optional[Union[List, Tuple, ndarray]]</code> <p>Homogeneous affine matrix. Provide a 2D list/tuple/ndarray with shape (spatial_ndims + 1, spatial_ndims + 1).</p> <code>None</code> <code>meta</code> <code>Optional[Dict | Meta]</code> <p>Free-form metadata dictionary or Meta instance. Must be JSON-serializable when saving.  If meta is passed as a Dict, it is internally converted into a <code>Meta</code> object with the dict stored as <code>meta.source</code>.</p> <code>None</code> <code>axis_labels</code> <code>Optional[List[Union[str, AxisLabel]]]</code> <p>Per-axis labels or roles. Length must match ndims. If None, the array is treated as purely spatial.</p> <code>None</code> <code>copy</code> <code>Optional[MLArray]</code> <p>Another MLArray instance to copy metadata fields from. If provided, its metadata overrides any metadata set via arguments.</p> <code>None</code> <code>patch_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Patch size hint for chunk/block optimization. Use <code>\"default\"</code> to use the default patch size of 192.</p> <code>'default'</code> <code>chunk_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit chunk size. Ignored when <code>patch_size</code> is provided.</p> <code>None</code> <code>block_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit block size. Ignored when <code>patch_size</code> is provided.</p> <code>None</code> <code>cparams</code> <code>Optional[Union[Dict, CParams]]</code> <p>Blosc2 compression parameters used when creating in-memory compressed array data.</p> <code>None</code> <code>dparams</code> <code>Optional[Union[Dict, DParams]]</code> <p>Blosc2 decompression parameters used for chunk access.</p> <code>None</code>"},{"location":"api/#mlarray.mlarray.MLArray.affine","title":"affine  <code>property</code> <code>writable</code>","text":"<pre><code>affine: ndarray\n</code></pre> <p>Computes the affine transformation matrix for the image.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>ndarray</code> <p>Affine matrix with shape (ndims + 1, ndims + 1), or None if no array is loaded.</p>"},{"location":"api/#mlarray.mlarray.MLArray.direction","title":"direction  <code>property</code> <code>writable</code>","text":"<pre><code>direction\n</code></pre> <p>Returns the image direction.</p> <p>Returns:</p> Name Type Description <code>list</code> <p>Direction cosine matrix with shape (ndims, ndims).</p>"},{"location":"api/#mlarray.mlarray.MLArray.dtype","title":"dtype  <code>property</code>","text":"<pre><code>dtype\n</code></pre> <p>Returns the dtype of the array.</p> <p>Returns:</p> Type Description <p>np.dtype: Dtype of the underlying array, or None if no array is loaded.</p>"},{"location":"api/#mlarray.mlarray.MLArray.ndim","title":"ndim  <code>property</code>","text":"<pre><code>ndim: int\n</code></pre> <p>Returns the number of spatial and non-spatial dimensions of the array.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of dimensions, or None if no array is loaded.</p>"},{"location":"api/#mlarray.mlarray.MLArray.origin","title":"origin  <code>property</code> <code>writable</code>","text":"<pre><code>origin\n</code></pre> <p>Returns the image origin.</p> <p>Returns:</p> Name Type Description <code>list</code> <p>Origin per spatial axis with length equal to the number of</p> <p>spatial dimensions.</p>"},{"location":"api/#mlarray.mlarray.MLArray.rotation","title":"rotation  <code>property</code>","text":"<pre><code>rotation\n</code></pre> <p>Extracts the rotation matrix from the affine matrix.</p> <p>Returns:</p> Name Type Description <code>list</code> <p>Rotation matrix with shape (ndims, ndims), or None if no array is loaded.</p>"},{"location":"api/#mlarray.mlarray.MLArray.scale","title":"scale  <code>property</code>","text":"<pre><code>scale\n</code></pre> <p>Extracts the scaling factors from the affine matrix.</p> <p>Returns:</p> Name Type Description <code>list</code> <p>Scaling factors per axis with length equal to the number of spatial dimensions, or None if no array is loaded.</p>"},{"location":"api/#mlarray.mlarray.MLArray.shape","title":"shape  <code>property</code>","text":"<pre><code>shape\n</code></pre> <p>Returns the shape of the array.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <p>Shape of the underlying array, or None if no array is loaded.</p>"},{"location":"api/#mlarray.mlarray.MLArray.shear","title":"shear  <code>property</code>","text":"<pre><code>shear\n</code></pre> <p>Computes the shear matrix from the affine matrix.</p> <p>Returns:</p> Name Type Description <code>list</code> <p>Shear matrix with shape (ndims, ndims), or None if no array is loaded.</p>"},{"location":"api/#mlarray.mlarray.MLArray.spacing","title":"spacing  <code>property</code> <code>writable</code>","text":"<pre><code>spacing\n</code></pre> <p>Returns the image spacing.</p> <p>Returns:</p> Name Type Description <code>list</code> <p>Spacing per spatial axis with length equal to the number of</p> <p>spatial dimensions.</p>"},{"location":"api/#mlarray.mlarray.MLArray.spatial_ndim","title":"spatial_ndim  <code>property</code>","text":"<pre><code>spatial_ndim: int\n</code></pre> <p>Returns the number of spatial dimensions.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of spatial dimensions, or None if no array is loaded.</p>"},{"location":"api/#mlarray.mlarray.MLArray.translation","title":"translation  <code>property</code>","text":"<pre><code>translation\n</code></pre> <p>Extracts the translation vector from the affine matrix.</p> <p>Returns:</p> Name Type Description <code>list</code> <p>Translation vector with length equal to the number of spatial dimensions, or None if no array is loaded.</p>"},{"location":"api/#mlarray.mlarray.MLArray.arange","title":"arange  <code>classmethod</code>","text":"<pre><code>arange(start: Union[int, float], stop: Optional[Union[int, float]] = None, step: Optional[Union[int, float]] = 1, dtype: dtype = None, shape: Optional[Union[int, List, Tuple, ndarray]] = None, c_order: bool = True, meta: Optional[Union[Dict, Meta]] = None, patch_size: Optional[Union[int, List, Tuple]] = None, chunk_size: Optional[Union[int, List, Tuple]] = None, block_size: Optional[Union[int, List, Tuple]] = None, cparams: Optional[Union[Dict, CParams]] = None, dparams: Optional[Union[Dict, DParams]] = None, compressed: bool = True)\n</code></pre> <p>Create an in-memory MLArray with evenly spaced values.</p> <p>Behavior mirrors :func:<code>blosc2.arange</code> while also applying MLArray metadata and chunk/block optimization settings.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>Union[int, float]</code> <p>Start of interval. If <code>stop</code> is None, this value is treated as stop and start becomes 0.</p> required <code>stop</code> <code>Optional[Union[int, float]]</code> <p>End of interval (exclusive).</p> <code>None</code> <code>step</code> <code>Optional[Union[int, float]]</code> <p>Spacing between values.</p> <code>1</code> <code>dtype</code> <code>dtype</code> <p>Output dtype. If None, inferred similarly to <code>blosc2.arange</code>.</p> <code>None</code> <code>shape</code> <code>Optional[Union[int, List, Tuple, ndarray]]</code> <p>Target output shape. If None, shape is inferred from start/stop/step.</p> <code>None</code> <code>c_order</code> <code>bool</code> <p>Store in C order (row-major) if True.</p> <code>True</code> <code>meta</code> <code>Optional[Union[Dict, Meta]]</code> <p>Optional metadata attached to the created <code>MLArray</code>.</p> <code>None</code> <code>patch_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Patch size hint for chunk/block optimization. Defaults to None for this method.</p> <code>None</code> <code>chunk_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit chunk size.</p> <code>None</code> <code>block_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit block size.</p> <code>None</code> <code>cparams</code> <code>Optional[Union[Dict, CParams]]</code> <p>Blosc2 compression parameters.</p> <code>None</code> <code>dparams</code> <code>Optional[Union[Dict, DParams]]</code> <p>Blosc2 decompression parameters.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>MLArray</code> <p>A newly created in-memory MLArray instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>shape</code> is inconsistent with <code>start</code>/<code>stop</code>/<code>step</code>.</p>"},{"location":"api/#mlarray.mlarray.MLArray.asarray","title":"asarray  <code>classmethod</code>","text":"<pre><code>asarray(array: Union[ndarray], meta: Optional[Union[Dict, Meta]] = None, patch_size: Optional[Union[int, List, Tuple]] = 'default', chunk_size: Optional[Union[int, List, Tuple]] = None, block_size: Optional[Union[int, List, Tuple]] = None, cparams: Optional[Union[Dict, CParams]] = None, dparams: Optional[Union[Dict, DParams]] = None, compressed: bool = True)\n</code></pre> <p>Convert a NumPy array into an in-memory Blosc2-backed MLArray.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>Union[ndarray]</code> <p>Input array to convert to MLArray.</p> required <code>meta</code> <code>Optional[Union[Dict, Meta]]</code> <p>Optional metadata attached to the created <code>MLArray</code>. Dict values are stored as <code>meta.source</code>.</p> <code>None</code> <code>patch_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Patch size hint for chunk/block optimization. Provide an int for isotropic sizes or a list/tuple with length equal to the number of dimensions. Use \"default\" to use the default patch size of 192.</p> <code>'default'</code> <code>chunk_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit chunk size. Provide an int or a tuple/list with length equal to the number of dimensions, or None to let Blosc2 decide. Ignored when patch_size is not None.</p> <code>None</code> <code>block_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit block size. Provide an int or a tuple/list with length equal to the number of dimensions, or None to let Blosc2 decide. Ignored when patch_size is not None.</p> <code>None</code> <code>cparams</code> <code>Optional[Union[Dict, CParams]]</code> <p>Blosc2 compression parameters used when creating the in-memory Blosc2 container (for example codec, compression level, and filters). Controls how data is compressed when stored. If None, defaults to <code>{'codec': blosc2.Codec.LZ4HC, 'clevel': 8}</code>.</p> <code>None</code> <code>dparams</code> <code>Optional[Union[Dict, DParams]]</code> <p>Blosc2 decompression parameters used when accessing compressed chunks (for example number of decompression threads). Controls runtime decompression behavior. If None, defaults to <code>{'nthreads': 1}</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>MLArray</code> <p>A newly created MLArray instance.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>array</code> is not a NumPy ndarray.</p> <code>ValueError</code> <p>If <code>meta</code> is not None, dict, or Meta.</p> <code>RuntimeError</code> <p>If patch/chunk/block arguments are inconsistent.</p> <code>NotImplementedError</code> <p>If automatic patch optimization is not implemented for the provided dimensionality.</p>"},{"location":"api/#mlarray.mlarray.MLArray.close","title":"close","text":"<pre><code>close()\n</code></pre> <p>Flush metadata and close the underlying store.</p> <p>After closing, the MLArray instance no longer has an attached array.</p>"},{"location":"api/#mlarray.mlarray.MLArray.comp_blosc2_params","title":"comp_blosc2_params  <code>classmethod</code>","text":"<pre><code>comp_blosc2_params(image_size: Union[Tuple[int, int], Tuple[int, int, int], Tuple[int, int, int, int]], patch_size: Union[Tuple[int, int], Tuple[int, int, int]], spatial_axis_mask: Optional[list[bool]] = None, bytes_per_pixel: int = 4, l1_cache_size_per_core_in_bytes: int = 32768, l3_cache_size_per_core_in_bytes: int = 1441792, safety_factor: float = 0.8)\n</code></pre> <p>Computes a recommended block and chunk size for saving arrays with Blosc v2.</p> <p>Blosc2 NDIM documentation: \"Having a second partition allows for greater flexibility in fitting different partitions to different CPU cache levels.  Typically, the first partition (also known as chunks) should be sized to fit within the L3 cache,  while the second partition (also known as blocks) should be sized to fit within the L2 or L1 caches,  depending on whether the priority is compression ratio or speed.\"  (Source: https://www.blosc.org/posts/blosc2-ndim-intro/)</p> <p>Our approach is not fully optimized for this yet.  Currently, we aim to fit the uncompressed block within the L1 cache, accepting that it might occasionally spill over into L2, which we consider acceptable.</p> <p>Note: This configuration is specifically optimized for nnU-Net data loading, where each read operation is performed by a single core, so multi-threading is not an option.</p> <p>The default cache values are based on an older Intel 4110 CPU with 32KB L1, 128KB L2, and 1408KB L3 cache per core.  We haven't further optimized for modern CPUs with larger caches, as our data must still be compatible with the older systems.</p> <p>Parameters:</p> Name Type Description Default <code>image_size</code> <code>Union[Tuple[int, int], Tuple[int, int, int], Tuple[int, int, int, int]]</code> <p>Image shape. Use a 2D, 3D, or 4D size; 2D/3D inputs are internally expanded to 4D (with non-spatial axes first).</p> required <code>patch_size</code> <code>Union[Tuple[int, int], Tuple[int, int, int]]</code> <p>Patch size for spatial dimensions. Use a 2-tuple (x, y) or 3-tuple (x, y, z).</p> required <code>spatial_axis_mask</code> <code>Optional[list[bool]]</code> <p>Mask indicating for every axis whether it is spatial or not.</p> <code>None</code> <code>bytes_per_pixel</code> <code>int</code> <p>Number of bytes per element. Defaults to 4 for float32.</p> <code>4</code> <code>l1_cache_size_per_core_in_bytes</code> <code>int</code> <p>L1 cache per core in bytes.</p> <code>32768</code> <code>l3_cache_size_per_core_in_bytes</code> <code>int</code> <p>L3 cache per core in bytes.</p> <code>1441792</code> <code>safety_factor</code> <code>float</code> <p>Safety factor to avoid filling caches.</p> <code>0.8</code> <p>Returns:</p> Type Description <p>Tuple[List[int], List[int]]: Recommended chunk size and block size.</p>"},{"location":"api/#mlarray.mlarray.MLArray.create","title":"create  <code>classmethod</code>","text":"<pre><code>create(filepath: Union[str, Path], shape: Union[List, Tuple, ndarray], dtype: dtype, meta: Optional[Union[Dict, Meta]] = None, mode: str = 'w', mmap_mode: str = 'w+', patch_size: Optional[Union[int, List, Tuple]] = 'default', chunk_size: Optional[Union[int, List, Tuple]] = None, block_size: Optional[Union[int, List, Tuple]] = None, cparams: Optional[Union[Dict, CParams]] = None, dparams: Optional[Union[Dict, DParams]] = None)\n</code></pre> <p>Create a new MLArray file with memory mapping.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Union[str, Path]</code> <p>Target file path. Must end with \".mla\".</p> required <code>shape</code> <code>Union[List, Tuple, ndarray]</code> <p>Shape of the array to create. If provided, a new file is created. Length must match the full array dimensionality (including non-spatial axes if present).</p> required <code>dtype</code> <code>dtype</code> <p>Numpy dtype for a newly created array.</p> required <code>meta</code> <code>Optional[Union[Dict, Meta]]</code> <p>Optional metadata attached to the created <code>MLArray</code>. Dict values are stored as <code>meta.source</code>.</p> <code>None</code> <code>mode</code> <code>str</code> <p>Controls storage open/creation permissions when using standard Blosc2 I/O (read-only, read/write, overwrite).  Does not affect lazy loading or decompression; data is accessed and decompressed on demand by Blosc2. Must be 'w' (default). Leave at default if unsure.</p> <code>'w'</code> <code>mmap_mode</code> <code>str</code> <p>Controls access via OS-level memory mapping of the compressed data, including read/write permissions.  Changes how bytes are fetched from disk (paging rather than explicit reads), while chunks are still decompressed on demand by Blosc2. Overrides <code>mode</code> if set. Must be either 'w+' (default) or None. Leave at default if unsure.</p> <code>'w+'</code> <code>patch_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Patch size hint for chunk/block optimization. Provide an int for isotropic sizes or a list/tuple with length equal to the number of spatial dimensions. Use \"default\" to use the default patch size of 192.</p> <code>'default'</code> <code>chunk_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit chunk size. Provide an int or tuple/list with length equal to the array dimensions. Ignored when <code>patch_size</code> is provided.</p> <code>None</code> <code>block_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit block size. Provide an int or tuple/list with length equal to the array dimensions. Ignored when <code>patch_size</code> is provided.</p> <code>None</code> <code>cparams</code> <code>Optional[Union[Dict, CParams]]</code> <p>Blosc2 compression parameters used when creating/writing array data (for example codec, compression level, and filters). Controls how data is compressed when stored. If None, defaults to <code>{'codec': blosc2.Codec.LZ4HC, 'clevel': 8}</code>.</p> <code>None</code> <code>dparams</code> <code>Optional[Union[Dict, DParams]]</code> <p>Blosc2 decompression parameters used when reading/accessing compressed chunks (for example number of decompression threads). Controls runtime decompression behavior. If None, defaults to <code>{'nthreads': 1}</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the file extension is invalid or if mode/mmap_mode is invalid for creation.</p>"},{"location":"api/#mlarray.mlarray.MLArray.empty","title":"empty  <code>classmethod</code>","text":"<pre><code>empty(shape: Union[int, List, Tuple, ndarray], dtype: dtype, meta: Optional[Union[Dict, Meta]] = None, patch_size: Optional[Union[int, List, Tuple]] = 'default', chunk_size: Optional[Union[int, List, Tuple]] = None, block_size: Optional[Union[int, List, Tuple]] = None, cparams: Optional[Union[Dict, CParams]] = None, dparams: Optional[Union[Dict, DParams]] = None, compressed: bool = True)\n</code></pre> <p>Create an in-memory MLArray with uninitialized values.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>Union[int, List, Tuple, ndarray]</code> <p>Shape of the output array.</p> required <code>dtype</code> <code>dtype</code> <p>Numpy dtype for the output array.</p> required <code>meta</code> <code>Optional[Union[Dict, Meta]]</code> <p>Optional metadata attached to the created <code>MLArray</code>. Dict values are stored as <code>meta.source</code>.</p> <code>None</code> <code>patch_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Patch size hint for chunk/block optimization. Use <code>\"default\"</code> to use the default patch size of 192.</p> <code>'default'</code> <code>chunk_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit chunk size. Ignored when <code>patch_size</code> is provided.</p> <code>None</code> <code>block_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit block size. Ignored when <code>patch_size</code> is provided.</p> <code>None</code> <code>cparams</code> <code>Optional[Union[Dict, CParams]]</code> <p>Blosc2 compression parameters used when writing chunks.</p> <code>None</code> <code>dparams</code> <code>Optional[Union[Dict, DParams]]</code> <p>Blosc2 decompression parameters used when reading chunks.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>MLArray</code> <p>A newly created in-memory MLArray instance.</p>"},{"location":"api/#mlarray.mlarray.MLArray.empty_like","title":"empty_like  <code>classmethod</code>","text":"<pre><code>empty_like(x, dtype: dtype = None, meta: Optional[Union[Dict, Meta]] = None, patch_size: Optional[Union[int, List, Tuple]] = 'default', chunk_size: Optional[Union[int, List, Tuple]] = None, block_size: Optional[Union[int, List, Tuple]] = None, cparams: Optional[Union[Dict, CParams]] = None, dparams: Optional[Union[Dict, DParams]] = None, compressed: bool = True)\n</code></pre> <p>Create an in-memory MLArray with the same shape as <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>Source object. Can be an <code>MLArray</code> or any array-like object exposing <code>shape</code> and <code>dtype</code>.</p> required <code>dtype</code> <code>dtype</code> <p>Output dtype. If None, inferred from <code>x</code>.</p> <code>None</code> <code>meta</code> <code>Optional[Union[Dict, Meta]]</code> <p>Optional metadata attached to the created <code>MLArray</code>. If <code>x</code> is an <code>MLArray</code> and <code>meta</code> is None, metadata is copied from <code>x</code>.</p> <code>None</code> <code>patch_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Patch size hint for chunk/block optimization.</p> <code>'default'</code> <code>chunk_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit chunk size.</p> <code>None</code> <code>block_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit block size.</p> <code>None</code> <code>cparams</code> <code>Optional[Union[Dict, CParams]]</code> <p>Blosc2 compression parameters.</p> <code>None</code> <code>dparams</code> <code>Optional[Union[Dict, DParams]]</code> <p>Blosc2 decompression parameters.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>MLArray</code> <p>A newly created in-memory MLArray instance.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>x</code> is not an <code>MLArray</code> and has no <code>shape</code>/<code>dtype</code>.</p>"},{"location":"api/#mlarray.mlarray.MLArray.full","title":"full  <code>classmethod</code>","text":"<pre><code>full(shape: Union[int, List, Tuple, ndarray], fill_value: Union[bytes, int, float, bool], dtype: dtype = None, meta: Optional[Union[Dict, Meta]] = None, patch_size: Optional[Union[int, List, Tuple]] = 'default', chunk_size: Optional[Union[int, List, Tuple]] = None, block_size: Optional[Union[int, List, Tuple]] = None, cparams: Optional[Union[Dict, CParams]] = None, dparams: Optional[Union[Dict, DParams]] = None, compressed: bool = True)\n</code></pre> <p>Create an in-memory MLArray filled with <code>fill_value</code>.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>Union[int, List, Tuple, ndarray]</code> <p>Shape of the output array.</p> required <code>fill_value</code> <code>Union[bytes, int, float, bool]</code> <p>Fill value used for all elements in the output.</p> required <code>dtype</code> <code>dtype</code> <p>Numpy dtype for the output array. If None, inferred from <code>fill_value</code>.</p> <code>None</code> <code>meta</code> <code>Optional[Union[Dict, Meta]]</code> <p>Optional metadata attached to the created <code>MLArray</code>.</p> <code>None</code> <code>patch_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Patch size hint for chunk/block optimization.</p> <code>'default'</code> <code>chunk_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit chunk size. Ignored when <code>patch_size</code> is provided.</p> <code>None</code> <code>block_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit block size. Ignored when <code>patch_size</code> is provided.</p> <code>None</code> <code>cparams</code> <code>Optional[Union[Dict, CParams]]</code> <p>Blosc2 compression parameters.</p> <code>None</code> <code>dparams</code> <code>Optional[Union[Dict, DParams]]</code> <p>Blosc2 decompression parameters.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>MLArray</code> <p>A newly created in-memory MLArray instance.</p>"},{"location":"api/#mlarray.mlarray.MLArray.full_like","title":"full_like  <code>classmethod</code>","text":"<pre><code>full_like(x, fill_value: Union[bool, int, float, complex], dtype: dtype = None, meta: Optional[Union[Dict, Meta]] = None, patch_size: Optional[Union[int, List, Tuple]] = 'default', chunk_size: Optional[Union[int, List, Tuple]] = None, block_size: Optional[Union[int, List, Tuple]] = None, cparams: Optional[Union[Dict, CParams]] = None, dparams: Optional[Union[Dict, DParams]] = None, compressed: bool = True)\n</code></pre> <p>Create an in-memory MLArray filled with <code>fill_value</code> and shape of <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>Source object. Can be an <code>MLArray</code> or any array-like object exposing <code>shape</code> and <code>dtype</code>.</p> required <code>fill_value</code> <code>Union[bool, int, float, complex]</code> <p>Fill value used for all elements in the output.</p> required <code>dtype</code> <code>dtype</code> <p>Output dtype. If None, inferred from <code>x</code>.</p> <code>None</code> <code>meta</code> <code>Optional[Union[Dict, Meta]]</code> <p>Optional metadata attached to the created <code>MLArray</code>. If <code>x</code> is an <code>MLArray</code> and <code>meta</code> is None, metadata is copied from <code>x</code>.</p> <code>None</code> <code>patch_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Patch size hint for chunk/block optimization.</p> <code>'default'</code> <code>chunk_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit chunk size.</p> <code>None</code> <code>block_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit block size.</p> <code>None</code> <code>cparams</code> <code>Optional[Union[Dict, CParams]]</code> <p>Blosc2 compression parameters.</p> <code>None</code> <code>dparams</code> <code>Optional[Union[Dict, DParams]]</code> <p>Blosc2 decompression parameters.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>MLArray</code> <p>A newly created in-memory MLArray instance.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>x</code> is not an <code>MLArray</code> and has no <code>shape</code>/<code>dtype</code>.</p>"},{"location":"api/#mlarray.mlarray.MLArray.linspace","title":"linspace  <code>classmethod</code>","text":"<pre><code>linspace(start: Union[int, float, complex], stop: Union[int, float, complex], num: Optional[int] = None, dtype: dtype = None, endpoint: bool = True, shape: Optional[Union[int, List, Tuple, ndarray]] = None, c_order: bool = True, meta: Optional[Union[Dict, Meta]] = None, patch_size: Optional[Union[int, List, Tuple]] = None, chunk_size: Optional[Union[int, List, Tuple]] = None, block_size: Optional[Union[int, List, Tuple]] = None, cparams: Optional[Union[Dict, CParams]] = None, dparams: Optional[Union[Dict, DParams]] = None, compressed: bool = True)\n</code></pre> <p>Create an in-memory MLArray with evenly spaced samples.</p> <p>Behavior mirrors :func:<code>blosc2.linspace</code> while also applying MLArray metadata and chunk/block optimization settings.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>Union[int, float, complex]</code> <p>Start value of the sequence.</p> required <code>stop</code> <code>Union[int, float, complex]</code> <p>End value of the sequence.</p> required <code>num</code> <code>Optional[int]</code> <p>Number of samples. Required when <code>shape</code> is None.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>Output dtype. If None, inferred similarly to <code>blosc2.linspace</code>.</p> <code>None</code> <code>endpoint</code> <code>bool</code> <p>Whether <code>stop</code> is included.</p> <code>True</code> <code>shape</code> <code>Optional[Union[int, List, Tuple, ndarray]]</code> <p>Target output shape. If None, inferred from <code>num</code>.</p> <code>None</code> <code>c_order</code> <code>bool</code> <p>Store in C order (row-major) if True.</p> <code>True</code> <code>meta</code> <code>Optional[Union[Dict, Meta]]</code> <p>Optional metadata attached to the created <code>MLArray</code>.</p> <code>None</code> <code>patch_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Patch size hint for chunk/block optimization. Defaults to None for this method.</p> <code>None</code> <code>chunk_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit chunk size.</p> <code>None</code> <code>block_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit block size.</p> <code>None</code> <code>cparams</code> <code>Optional[Union[Dict, CParams]]</code> <p>Blosc2 compression parameters.</p> <code>None</code> <code>dparams</code> <code>Optional[Union[Dict, DParams]]</code> <p>Blosc2 decompression parameters.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>MLArray</code> <p>A newly created in-memory MLArray instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither <code>shape</code> nor <code>num</code> is specified, or if the provided <code>shape</code> and <code>num</code> are inconsistent.</p>"},{"location":"api/#mlarray.mlarray.MLArray.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(filepath: Union[str, Path], dparams: Optional[Union[Dict, DParams]] = None, compressed: bool = True)\n</code></pre> <p>Load a MLArray file as a whole without memory mapping.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Union[str, Path]</code> <p>Path to the MLArray file to be loaded. The filepath needs to have the extension \".mla\".</p> required <code>dparams</code> <code>Optional[Union[Dict, DParams]]</code> <p>Blosc2 decompression parameters used when loading/accessing compressed chunks. If None, defaults to <code>{'nthreads': 1}</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the file extension is not \".mla\".</p>"},{"location":"api/#mlarray.mlarray.MLArray.ones","title":"ones  <code>classmethod</code>","text":"<pre><code>ones(shape: Union[int, List, Tuple, ndarray], dtype: dtype = None, meta: Optional[Union[Dict, Meta]] = None, patch_size: Optional[Union[int, List, Tuple]] = 'default', chunk_size: Optional[Union[int, List, Tuple]] = None, block_size: Optional[Union[int, List, Tuple]] = None, cparams: Optional[Union[Dict, CParams]] = None, dparams: Optional[Union[Dict, DParams]] = None, compressed: bool = True)\n</code></pre> <p>Create an in-memory MLArray filled with ones.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>Union[int, List, Tuple, ndarray]</code> <p>Shape of the output array.</p> required <code>dtype</code> <code>dtype</code> <p>Numpy dtype for the output array. If None, uses <code>blosc2.DEFAULT_FLOAT</code>.</p> <code>None</code> <code>meta</code> <code>Optional[Union[Dict, Meta]]</code> <p>Optional metadata attached to the created <code>MLArray</code>.</p> <code>None</code> <code>patch_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Patch size hint for chunk/block optimization.</p> <code>'default'</code> <code>chunk_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit chunk size. Ignored when <code>patch_size</code> is provided.</p> <code>None</code> <code>block_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit block size. Ignored when <code>patch_size</code> is provided.</p> <code>None</code> <code>cparams</code> <code>Optional[Union[Dict, CParams]]</code> <p>Blosc2 compression parameters.</p> <code>None</code> <code>dparams</code> <code>Optional[Union[Dict, DParams]]</code> <p>Blosc2 decompression parameters.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>MLArray</code> <p>A newly created in-memory MLArray instance.</p>"},{"location":"api/#mlarray.mlarray.MLArray.ones_like","title":"ones_like  <code>classmethod</code>","text":"<pre><code>ones_like(x, dtype: dtype = None, meta: Optional[Union[Dict, Meta]] = None, patch_size: Optional[Union[int, List, Tuple]] = 'default', chunk_size: Optional[Union[int, List, Tuple]] = None, block_size: Optional[Union[int, List, Tuple]] = None, cparams: Optional[Union[Dict, CParams]] = None, dparams: Optional[Union[Dict, DParams]] = None, compressed: bool = True)\n</code></pre> <p>Create an in-memory MLArray of ones with the same shape as <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>Source object. Can be an <code>MLArray</code> or any array-like object exposing <code>shape</code> and <code>dtype</code>.</p> required <code>dtype</code> <code>dtype</code> <p>Output dtype. If None, inferred from <code>x</code>.</p> <code>None</code> <code>meta</code> <code>Optional[Union[Dict, Meta]]</code> <p>Optional metadata attached to the created <code>MLArray</code>. If <code>x</code> is an <code>MLArray</code> and <code>meta</code> is None, metadata is copied from <code>x</code>.</p> <code>None</code> <code>patch_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Patch size hint for chunk/block optimization.</p> <code>'default'</code> <code>chunk_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit chunk size.</p> <code>None</code> <code>block_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit block size.</p> <code>None</code> <code>cparams</code> <code>Optional[Union[Dict, CParams]]</code> <p>Blosc2 compression parameters.</p> <code>None</code> <code>dparams</code> <code>Optional[Union[Dict, DParams]]</code> <p>Blosc2 decompression parameters.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>MLArray</code> <p>A newly created in-memory MLArray instance.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>x</code> is not an <code>MLArray</code> and has no <code>shape</code>/<code>dtype</code>.</p>"},{"location":"api/#mlarray.mlarray.MLArray.open","title":"open  <code>classmethod</code>","text":"<pre><code>open(filepath: Union[str, Path], mode: str = 'r', mmap_mode: str = 'r', dparams: Optional[Union[Dict, DParams]] = None)\n</code></pre> <p>Open an existing MLArray file with memory mapping.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Union[str, Path]</code> <p>Target file path. Must end with \".mla\".</p> required <code>mode</code> <code>str</code> <p>Controls storage open/creation permissions when using standard Blosc2 I/O (read-only, read/write, overwrite).  Does not affect lazy loading or decompression; data is accessed and decompressed on demand by Blosc2. Must be either 'r' (default) or 'a'. Leave at default if unsure.</p> <code>'r'</code> <code>mmap_mode</code> <code>str</code> <p>Controls access via OS-level memory mapping of the compressed data, including read/write permissions.  Changes how bytes are fetched from disk (paging rather than explicit reads), while chunks are still decompressed on demand by Blosc2. Overrides <code>mode</code> if set. Must be either 'r' (default), 'r+', 'c' or None. Leave at default if unsure.</p> <code>'r'</code> <code>dparams</code> <code>Optional[Union[Dict, DParams]]</code> <p>Blosc2 decompression parameters used when reading/accessing compressed chunks (for example number of decompression threads). Controls runtime decompression behavior. If None, defaults to <code>{'nthreads': 1}</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the file extension is invalid or if mode/mmap_mode is invalid for opening.</p>"},{"location":"api/#mlarray.mlarray.MLArray.save","title":"save","text":"<pre><code>save(filepath: Union[str, Path])\n</code></pre> <p>Save the array to a MLArray file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Union[str, Path]</code> <p>Path to save the file. Must end with \".mla\".</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the file extension is not \".mla\".</p>"},{"location":"api/#mlarray.mlarray.MLArray.to_numpy","title":"to_numpy","text":"<pre><code>to_numpy()\n</code></pre> <p>Return the underlying data as a NumPy array.</p> <p>Returns:</p> Type Description <p>np.ndarray: A NumPy view or copy of the stored array data.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If no array data is loaded.</p>"},{"location":"api/#mlarray.mlarray.MLArray.zeros","title":"zeros  <code>classmethod</code>","text":"<pre><code>zeros(shape: Union[int, List, Tuple, ndarray], dtype: dtype, meta: Optional[Union[Dict, Meta]] = None, patch_size: Optional[Union[int, List, Tuple]] = 'default', chunk_size: Optional[Union[int, List, Tuple]] = None, block_size: Optional[Union[int, List, Tuple]] = None, cparams: Optional[Union[Dict, CParams]] = None, dparams: Optional[Union[Dict, DParams]] = None, compressed: bool = True)\n</code></pre> <p>Create an in-memory MLArray filled with zeros.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>Union[int, List, Tuple, ndarray]</code> <p>Shape of the output array.</p> required <code>dtype</code> <code>dtype</code> <p>Numpy dtype for the output array.</p> required <code>meta</code> <code>Optional[Union[Dict, Meta]]</code> <p>Optional metadata attached to the created <code>MLArray</code>.</p> <code>None</code> <code>patch_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Patch size hint for chunk/block optimization.</p> <code>'default'</code> <code>chunk_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit chunk size. Ignored when <code>patch_size</code> is provided.</p> <code>None</code> <code>block_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit block size. Ignored when <code>patch_size</code> is provided.</p> <code>None</code> <code>cparams</code> <code>Optional[Union[Dict, CParams]]</code> <p>Blosc2 compression parameters.</p> <code>None</code> <code>dparams</code> <code>Optional[Union[Dict, DParams]]</code> <p>Blosc2 decompression parameters.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>MLArray</code> <p>A newly created in-memory MLArray instance.</p>"},{"location":"api/#mlarray.mlarray.MLArray.zeros_like","title":"zeros_like  <code>classmethod</code>","text":"<pre><code>zeros_like(x, dtype: dtype = None, meta: Optional[Union[Dict, Meta]] = None, patch_size: Optional[Union[int, List, Tuple]] = 'default', chunk_size: Optional[Union[int, List, Tuple]] = None, block_size: Optional[Union[int, List, Tuple]] = None, cparams: Optional[Union[Dict, CParams]] = None, dparams: Optional[Union[Dict, DParams]] = None, compressed: bool = True)\n</code></pre> <p>Create an in-memory MLArray of zeros with the same shape as <code>x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>Source object. Can be an <code>MLArray</code> or any array-like object exposing <code>shape</code> and <code>dtype</code>.</p> required <code>dtype</code> <code>dtype</code> <p>Output dtype. If None, inferred from <code>x</code>.</p> <code>None</code> <code>meta</code> <code>Optional[Union[Dict, Meta]]</code> <p>Optional metadata attached to the created <code>MLArray</code>. If <code>x</code> is an <code>MLArray</code> and <code>meta</code> is None, metadata is copied from <code>x</code>.</p> <code>None</code> <code>patch_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Patch size hint for chunk/block optimization.</p> <code>'default'</code> <code>chunk_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit chunk size.</p> <code>None</code> <code>block_size</code> <code>Optional[Union[int, List, Tuple]]</code> <p>Explicit block size.</p> <code>None</code> <code>cparams</code> <code>Optional[Union[Dict, CParams]]</code> <p>Blosc2 compression parameters.</p> <code>None</code> <code>dparams</code> <code>Optional[Union[Dict, DParams]]</code> <p>Blosc2 decompression parameters.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>MLArray</code> <p>A newly created in-memory MLArray instance.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>x</code> is not an <code>MLArray</code> and has no <code>shape</code>/<code>dtype</code>.</p>"},{"location":"api/#metadata-module","title":"Metadata Module","text":""},{"location":"api/#mlarray.meta.BaseMeta","title":"mlarray.meta.BaseMeta  <code>dataclass</code>","text":"<pre><code>BaseMeta()\n</code></pre> <p>Base class for metadata containers.</p> <p>Subclasses should implement _validate_and_cast to coerce and validate fields after initialization or mutation.</p>"},{"location":"api/#mlarray.meta.BaseMeta.copy_from","title":"copy_from","text":"<pre><code>copy_from(other: T, *, overwrite: bool = False) -&gt; None\n</code></pre> <p>Copy fields from another instance of the same class.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>T</code> <p>Source instance.</p> required <code>overwrite</code> <code>bool</code> <p>When True, overwrite all fields. When False, only fill destination fields that are \"unset\" (None or empty containers). Nested BaseMeta fields are merged recursively unless the entire destination sub-meta is default, in which case it is replaced.</p> <code>False</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If other is not the same class as self.</p>"},{"location":"api/#mlarray.meta.BaseMeta.ensure","title":"ensure  <code>classmethod</code>","text":"<pre><code>ensure(x: Any) -&gt; T\n</code></pre> <p>Coerce x into an instance of cls.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Any</code> <p>None, an instance of cls, or a mapping of fields.</p> required <p>Returns:</p> Type Description <code>T</code> <p>An instance of cls.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If x is not None, cls, or a mapping.</p>"},{"location":"api/#mlarray.meta.BaseMeta.from_mapping","title":"from_mapping  <code>classmethod</code>","text":"<pre><code>from_mapping(d: Mapping[str, Any]) -&gt; T\n</code></pre> <p>Construct an instance from a mapping.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>Mapping[str, Any]</code> <p>Input mapping matching dataclass field names.</p> required <p>Returns:</p> Type Description <code>T</code> <p>A new instance of cls.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If d is not a Mapping.</p> <code>KeyError</code> <p>If unknown keys are present.</p>"},{"location":"api/#mlarray.meta.BaseMeta.is_default","title":"is_default","text":"<pre><code>is_default() -&gt; bool\n</code></pre> <p>Return True if this equals a default-constructed instance.</p>"},{"location":"api/#mlarray.meta.BaseMeta.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset all fields to their default or None.</p>"},{"location":"api/#mlarray.meta.BaseMeta.to_mapping","title":"to_mapping","text":"<pre><code>to_mapping(*, include_none: bool = True) -&gt; dict[str, Any]\n</code></pre> <p>Serialize to a mapping, recursively expanding nested BaseMeta.</p> <p>Parameters:</p> Name Type Description Default <code>include_none</code> <code>bool</code> <p>Include fields with None values when True.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>A dict of field names to serialized values.</p>"},{"location":"api/#mlarray.meta.BaseMeta.to_plain","title":"to_plain","text":"<pre><code>to_plain(*, include_none: bool = False) -&gt; Any\n</code></pre> <p>Convert to plain Python objects recursively.</p> <p>Parameters:</p> Name Type Description Default <code>include_none</code> <code>bool</code> <p>Include fields with None values when True.</p> <code>False</code> <p>Returns:</p> Type Description <code>Any</code> <p>A dict of field values, with nested BaseMeta expanded. SingleKeyBaseMeta</p> <code>Any</code> <p>overrides this to return its wrapped value.</p>"},{"location":"api/#mlarray.meta.SingleKeyBaseMeta","title":"mlarray.meta.SingleKeyBaseMeta  <code>dataclass</code>","text":"<pre><code>SingleKeyBaseMeta()\n</code></pre> <p>               Bases: <code>BaseMeta</code></p> <p>BaseMeta subclass that wraps a single field as a raw value.</p>"},{"location":"api/#mlarray.meta.SingleKeyBaseMeta.value","title":"value  <code>property</code> <code>writable</code>","text":"<pre><code>value: Any\n</code></pre> <p>Return the wrapped value.</p>"},{"location":"api/#mlarray.meta.SingleKeyBaseMeta.ensure","title":"ensure  <code>classmethod</code>","text":"<pre><code>ensure(x: Any) -&gt; SK\n</code></pre> <p>Coerce input into an instance of cls.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Any</code> <p>None, instance of cls, mapping, or raw value.</p> required <p>Returns:</p> Type Description <code>SK</code> <p>An instance of cls.</p>"},{"location":"api/#mlarray.meta.SingleKeyBaseMeta.from_mapping","title":"from_mapping  <code>classmethod</code>","text":"<pre><code>from_mapping(d: Any) -&gt; SK\n</code></pre> <p>Construct from either schema-shaped mapping or raw value.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>Any</code> <p>None, mapping, or raw value.</p> required <p>Returns:</p> Type Description <code>SK</code> <p>A new instance of cls.</p>"},{"location":"api/#mlarray.meta.SingleKeyBaseMeta.set","title":"set","text":"<pre><code>set(v: Any) -&gt; None\n</code></pre> <p>Set the wrapped value.</p>"},{"location":"api/#mlarray.meta.SingleKeyBaseMeta.to_mapping","title":"to_mapping","text":"<pre><code>to_mapping(*, include_none: bool = True) -&gt; dict[str, Any]\n</code></pre> <p>Serialize to a mapping with the single key.</p> <p>Parameters:</p> Name Type Description Default <code>include_none</code> <code>bool</code> <p>Include the key when the value is None.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>A dict with the single field name as the key, or an empty dict.</p>"},{"location":"api/#mlarray.meta.SingleKeyBaseMeta.to_plain","title":"to_plain","text":"<pre><code>to_plain(*, include_none: bool = False) -&gt; Any\n</code></pre> <p>Return the wrapped value for plain output.</p> <p>Parameters:</p> Name Type Description Default <code>include_none</code> <code>bool</code> <p>Return None when the value is None.</p> <code>False</code> <p>Returns:</p> Type Description <code>Any</code> <p>The wrapped value or None.</p>"},{"location":"api/#mlarray.meta.Meta","title":"mlarray.meta.Meta  <code>dataclass</code>","text":"<pre><code>Meta(source: 'MetaSource' = (lambda: MetaSource())(), extra: 'MetaExtra' = (lambda: MetaExtra())(), spatial: 'MetaSpatial' = (lambda: MetaSpatial())(), stats: 'MetaStatistics' = (lambda: MetaStatistics())(), bbox: 'MetaBbox' = (lambda: MetaBbox())(), is_seg: 'MetaIsSeg' = (lambda: MetaIsSeg())(), blosc2: 'MetaBlosc2' = (lambda: MetaBlosc2())(), _has_array: 'MetaHasArray' = (lambda: MetaHasArray())(), _image_meta_format: 'MetaImageFormat' = (lambda: MetaImageFormat())(), _mlarray_version: 'MetaVersion' = (lambda: MetaVersion())())\n</code></pre> <p>               Bases: <code>BaseMeta</code></p> <p>Top-level metadata container for mlarray.</p> <p>Attributes:</p> Name Type Description <code>source</code> <code>'MetaSource'</code> <p>Source metadata from the original image source (JSON-serializable dict).</p> <code>extra</code> <code>'MetaExtra'</code> <p>Additional metadata (JSON-serializable dict).</p> <code>spatial</code> <code>'MetaSpatial'</code> <p>Spatial metadata (spacing, origin, direction, affine, shape).</p> <code>stats</code> <code>'MetaStatistics'</code> <p>Summary statistics.</p> <code>bbox</code> <code>'MetaBbox'</code> <p>Bounding boxes.</p> <code>is_seg</code> <code>'MetaIsSeg'</code> <p>Segmentation flag.</p> <code>blosc2</code> <code>'MetaBlosc2'</code> <p>Blosc2 chunking/tiling metadata.</p> <code>_has_array</code> <code>'MetaHasArray'</code> <p>Payload presence flag.</p> <code>_image_meta_format</code> <code>'MetaImageFormat'</code> <p>Image metadata format identifier.</p> <code>_mlarray_version</code> <code>'MetaVersion'</code> <p>Version string for mlarray.</p>"},{"location":"api/#mlarray.meta.Meta.to_plain","title":"to_plain","text":"<pre><code>to_plain(*, include_none: bool = False) -&gt; Any\n</code></pre> <p>Convert to plain values, suppressing default sub-metas.</p> <p>Parameters:</p> Name Type Description Default <code>include_none</code> <code>bool</code> <p>Include None values when True.</p> <code>False</code> <p>Returns:</p> Type Description <code>Any</code> <p>A dict of field values where default child metas are represented</p> <code>Any</code> <p>as None and optionally filtered out.</p>"},{"location":"api/#mlarray.meta.MetaSource","title":"mlarray.meta.MetaSource  <code>dataclass</code>","text":"<pre><code>MetaSource(data: dict[str, Any] = dict())\n</code></pre> <p>               Bases: <code>SingleKeyBaseMeta</code></p> <p>Source metadata from the original image source stored as JSON-serializable dict.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>dict[str, Any]</code> <p>Arbitrary JSON-serializable metadata.</p>"},{"location":"api/#mlarray.meta.MetaExtra","title":"mlarray.meta.MetaExtra  <code>dataclass</code>","text":"<pre><code>MetaExtra(data: dict[str, Any] = dict())\n</code></pre> <p>               Bases: <code>SingleKeyBaseMeta</code></p> <p>Generic extra metadata stored as JSON-serializable dict.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>dict[str, Any]</code> <p>Arbitrary JSON-serializable metadata.</p>"},{"location":"api/#mlarray.meta.MetaSpatial","title":"mlarray.meta.MetaSpatial  <code>dataclass</code>","text":"<pre><code>MetaSpatial(spacing: Optional[list[Union[int, float]]] = None, origin: Optional[list[Union[int, float]]] = None, direction: Optional[list[list[Union[int, float]]]] = None, affine: Optional[list[list[Union[int, float]]]] = None, shape: Optional[list[int]] = None, axis_labels: Optional[list[Union[str, AxisLabel]]] = None, axis_units: Optional[list[str]] = None, _num_spatial_axes: Optional[int] = None, _num_non_spatial_axes: Optional[int] = None)\n</code></pre> <p>               Bases: <code>BaseMeta</code></p> <p>Spatial metadata describing geometry and layout.</p> <p>Attributes:</p> Name Type Description <code>spacing</code> <code>Optional[list[Union[int, float]]]</code> <p>Per-dimension spacing values. Length must match ndims.</p> <code>origin</code> <code>Optional[list[Union[int, float]]]</code> <p>Per-dimension origin values. Length must match ndims.</p> <code>direction</code> <code>Optional[list[list[Union[int, float]]]]</code> <p>Direction cosine matrix of shape [ndims, ndims].</p> <code>affine</code> <code>Optional[list[list[Union[int, float]]]]</code> <p>Homogeneous affine matrix of shape [ndims + 1, ndims + 1].</p> <code>shape</code> <code>Optional[list[int]]</code> <p>Array shape. Length must match (spatial + non-spatial) ndims.</p> <code>axis_labels</code> <code>Optional[list[Union[str, AxisLabel]]]</code> <p>Per-axis labels or roles. Length must match ndims.</p> <code>axis_units</code> <code>Optional[list[str]]</code> <p>Per-axis units. Length must match ndims.</p> <code>_num_spatial_axes</code> <code>Optional[int]</code> <p>Cached count of spatial axes derived from axis_labels.</p> <code>_num_non_spatial_axes</code> <code>Optional[int]</code> <p>Cached count of non-spatial axes derived from axis_labels.</p>"},{"location":"api/#mlarray.meta.AxisLabelEnum","title":"mlarray.meta.AxisLabelEnum","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Axis label/role identifiers used for spatial metadata.</p> <p>Attributes:</p> Name Type Description <code>spatial</code> <p>Generic spatial axis (used when no axis-specific label applies).</p> <code>spatial_x</code> <p>Spatial axis representing X.</p> <code>spatial_y</code> <p>Spatial axis representing Y.</p> <code>spatial_z</code> <p>Spatial axis representing Z.</p> <code>non_spatial</code> <p>Generic non-spatial axis.</p> <code>channel</code> <p>Channel axis (e.g., color channels or feature maps).</p> <code>temporal</code> <p>Time axis.</p> <code>continuous</code> <p>Continuous-valued axis (non-spatial).</p> <code>components</code> <p>Component axis (e.g., vector components).</p>"},{"location":"api/#mlarray.meta.MetaStatistics","title":"mlarray.meta.MetaStatistics  <code>dataclass</code>","text":"<pre><code>MetaStatistics(min: Optional[float] = None, max: Optional[float] = None, mean: Optional[float] = None, median: Optional[float] = None, std: Optional[float] = None, percentile_min: Optional[float] = None, percentile_max: Optional[float] = None, percentile_mean: Optional[float] = None, percentile_median: Optional[float] = None, percentile_std: Optional[float] = None, percentile_min_key: Optional[float] = None, percentile_max_key: Optional[float] = None)\n</code></pre> <p>               Bases: <code>BaseMeta</code></p> <p>Numeric summary statistics for an array.</p> <p>Attributes:</p> Name Type Description <code>min</code> <code>Optional[float]</code> <p>Minimum value.</p> <code>max</code> <code>Optional[float]</code> <p>Maximum value.</p> <code>mean</code> <code>Optional[float]</code> <p>Mean value.</p> <code>median</code> <code>Optional[float]</code> <p>Median value.</p> <code>std</code> <code>Optional[float]</code> <p>Standard deviation.</p> <code>percentile_min</code> <code>Optional[float]</code> <p>Minimum percentile value.</p> <code>percentile_max</code> <code>Optional[float]</code> <p>Maximum percentile value.</p> <code>percentile_mean</code> <code>Optional[float]</code> <p>Mean percentile value.</p> <code>percentile_median</code> <code>Optional[float]</code> <p>Median percentile value.</p> <code>percentile_std</code> <code>Optional[float]</code> <p>Standard deviation of percentile values.</p> <code>percentile_min_key</code> <code>Optional[float]</code> <p>Minimum percentile key used to determine percentile_min (for example 0.05).</p> <code>percentile_max_key</code> <code>Optional[float]</code> <p>Maximum percentile key used to determine percentile_max (for example 0.95).</p>"},{"location":"api/#mlarray.meta.MetaBbox","title":"mlarray.meta.MetaBbox  <code>dataclass</code>","text":"<pre><code>MetaBbox(bboxes: Optional[list[list[list[Union[int, float]]]]] = None, scores: Optional[list[Union[int, float]]] = None, labels: Optional[list[Union[str, int, float]]] = None)\n</code></pre> <p>               Bases: <code>BaseMeta</code></p> <p>Bounding box metadata with optional scores and labels.</p> <p>Attributes:</p> Name Type Description <code>bboxes</code> <code>Optional[list[list[list[Union[int, float]]]]]</code> <p>List of bounding boxes with shape [n_boxes, ndims, 2], where each inner pair is [min, max] for a dimension. Values must be ints or floats.</p> <code>scores</code> <code>Optional[list[Union[int, float]]]</code> <p>Optional confidence scores aligned with bboxes (ints or floats).</p> <code>labels</code> <code>Optional[list[Union[str, int, float]]]</code> <p>Optional labels aligned with bboxes. Each label may be a string, int, or float.</p>"},{"location":"api/#mlarray.meta.MetaIsSeg","title":"mlarray.meta.MetaIsSeg  <code>dataclass</code>","text":"<pre><code>MetaIsSeg(is_seg: Optional[bool] = None)\n</code></pre> <p>               Bases: <code>SingleKeyBaseMeta</code></p> <p>Flag indicating whether the array is a segmentation mask.</p> <p>Attributes:</p> Name Type Description <code>is_seg</code> <code>Optional[bool]</code> <p>True/False when known, None when unknown.</p>"},{"location":"api/#mlarray.meta.MetaBlosc2","title":"mlarray.meta.MetaBlosc2  <code>dataclass</code>","text":"<pre><code>MetaBlosc2(chunk_size: Optional[list] = None, block_size: Optional[list] = None, patch_size: Optional[list] = None, cparams: Optional[dict[str, Any]] = None, dparams: Optional[dict[str, Any]] = None)\n</code></pre> <p>               Bases: <code>BaseMeta</code></p> <p>Metadata for Blosc2 tiling and chunking.</p> <p>Attributes:</p> Name Type Description <code>chunk_size</code> <code>Optional[list]</code> <p>List of per-dimension chunk sizes. Length must match ndims.</p> <code>block_size</code> <code>Optional[list]</code> <p>List of per-dimension block sizes. Length must match ndims.</p> <code>patch_size</code> <code>Optional[list]</code> <p>List of per-dimension patch sizes. Length must match spatial ndims.</p> <code>cparams</code> <code>Optional[dict[str, Any]]</code> <p>Blosc2 compression parameters as a JSON-serializable dict.</p> <code>dparams</code> <code>Optional[dict[str, Any]]</code> <p>Blosc2 decompression parameters as a JSON-serializable dict.</p>"},{"location":"api/#mlarray.meta.MetaHasArray","title":"mlarray.meta.MetaHasArray  <code>dataclass</code>","text":"<pre><code>MetaHasArray(has_array: bool = False)\n</code></pre> <p>               Bases: <code>SingleKeyBaseMeta</code></p> <p>Flag indicating whether an array is present.</p> <p>Attributes:</p> Name Type Description <code>has_array</code> <code>bool</code> <p>True when array data is present.</p>"},{"location":"api/#mlarray.meta.MetaImageFormat","title":"mlarray.meta.MetaImageFormat  <code>dataclass</code>","text":"<pre><code>MetaImageFormat(image_meta_format: Optional[str] = None)\n</code></pre> <p>               Bases: <code>SingleKeyBaseMeta</code></p> <p>String describing the image metadata format.</p> <p>Attributes:</p> Name Type Description <code>image_meta_format</code> <code>Optional[str]</code> <p>Format identifier, or None.</p>"},{"location":"api/#mlarray.meta.MetaVersion","title":"mlarray.meta.MetaVersion  <code>dataclass</code>","text":"<pre><code>MetaVersion(mlarray_version: Optional[str] = None)\n</code></pre> <p>               Bases: <code>SingleKeyBaseMeta</code></p> <p>Version metadata for mlarray.</p> <p>Attributes:</p> Name Type Description <code>mlarray_version</code> <code>Optional[str]</code> <p>Version string, or None.</p>"},{"location":"cli/","title":"CLI","text":"<p>MLArray includes a small command-line interface for common tasks such as inspecting file headers and converting existing image formats into MLArray. This is especially useful when you want to quickly verify metadata, debug a dataset, or batch-convert files without writing Python code.</p> <p>The CLI currently focuses on core workflows (header inspection and conversion). Support for converting a wider range of image formats will be added over time.</p>"},{"location":"cli/#mlarray_header","title":"<code>mlarray_header</code>","text":"<p>Print the metadata header from a <code>.mla</code> file.</p> <p>This command is useful for quickly checking spatial metadata, stored schemas, and other file-level information without loading the full array into memory.</p> <pre><code>mlarray_header sample.mla\n</code></pre>"},{"location":"cli/#mlarray_convert","title":"<code>mlarray_convert</code>","text":"<p>Convert a NIfTI or NRRD file to MLArray and copy metadata.</p> <p>This provides an easy way to bring existing medical imaging data into an MLArray-based workflow while preserving the original metadata for downstream analysis and visualization.</p> <pre><code>mlarray_convert sample.nii.gz output.mla\n</code></pre>"},{"location":"optimization/","title":"ML Optimization","text":"<p>MLArray is designed around a simple goal: make training-time I/O fast and predictable, especially for large N-D images where reading full volumes is impractical. Most ML pipelines repeatedly sample small patches/crops (e.g., nnU-Net-style random patch sampling) and the storage layout should match that access pattern.</p> <p>To achieve this, MLArray builds on Blosc2 ND arrays, which store data in a two-level tiled layout:</p> <ul> <li>Chunks: larger partitions that are typically sized to fit higher-level CPU caches (and amortize overhead).</li> <li>Blocks: smaller partitions inside chunks that are typically sized to fit lower-level CPU caches and improve decompression speed.</li> </ul> <p>On top of that, MLArray supports memory-mapped access via Blosc2, so reading <code>image[x0:x1, y0:y1, ...]</code> can touch only the required on-disk regions, instead of loading the whole array.</p> <p>The key challenge is that choosing good <code>chunk_size</code> and <code>block_size</code> is hard:</p> <ul> <li>the optimal values depend on CPU cache sizes, dtype, dimensionality, and\u2014most importantly\u2014your training patch size,</li> <li>and the wrong choices can silently tank throughput.</li> </ul>"},{"location":"optimization/#patch-size-driven-layout-optimization","title":"Patch-size-driven layout optimization","text":"<p>Instead of requiring users to be storage experts, MLArray introduces a patch size optimization:</p> <ol> <li>You tell MLArray the patch size you expect to sample during training (e.g., <code>192\u00b3</code>).</li> <li>MLArray derives block_size and chunk_size automatically to match this access pattern.</li> <li> <p>Internally, the heuristic considers:</p> </li> <li> <p>element size (bytes per pixel),</p> </li> <li>CPU cache sizes (L1 / L3 per core),</li> <li>your patch size (2D or 3D),</li> <li>non-spatial axes layout (via <code>axis_labels</code>),</li> <li>and then chooses block/chunk sizes that aim to keep decompression and reads cache-friendly.</li> </ol> <p>Practically: this means reading a training patch should tend to require as few chunk/block touches as possible, while keeping the decompressed working set aligned with CPU caches.</p>"},{"location":"optimization/#when-should-i-care","title":"When should I care?","text":"<ul> <li>If you train with patch sampling (most medical imaging pipelines do): set <code>patch_size</code>.</li> <li>If you do mostly full-volume reads: patch sizing matters less; larger chunks may be fine.</li> <li>If you have a very specific access pattern or hardware constraint: set <code>chunk_size</code> / <code>block_size</code> manually.</li> </ul>"},{"location":"optimization/#usage-patterns","title":"Usage patterns","text":"<p>Below are common end-to-end workflows. The examples show the important knobs and what they do.</p>"},{"location":"optimization/#1-just-do-the-right-thing-recommended","title":"1) \u201cJust do the right thing\u201d (recommended)","text":"<p>Use the default patch size optimization. If you don\u2019t specify anything, MLArray uses an isotropic default patch size of 192 (per spatial axis) and derives chunk/block sizes automatically.</p> <pre><code>import numpy as np\nfrom mlarray import MLArray\n\narray = np.random.random((128, 256, 256))\nimage = MLArray(array)\n\n# Uses patch_size='default' (192) -&gt; auto-derives chunk/block sizes\nimage.save(\"default-opt.mla\")\n</code></pre> <p>When to use:</p> <ul> <li>you want good performance without tuning,</li> <li>your training patch size is close to ~192 (common in many 3D pipelines).</li> </ul>"},{"location":"optimization/#2-optimize-explicitly-for-your-training-patch-size","title":"2) Optimize explicitly for your training patch size","text":"<p>If you know your sampler will draw patches of a specific size, set <code>patch_size</code> accordingly. This makes the on-disk layout match your training-time reads more closely.</p> <pre><code>import numpy as np\nfrom mlarray import MLArray\n\narray = np.random.random((128, 256, 256))\nimage = MLArray(array, patch_size=(128, 192, 256))\n\n# Optimize storage layout for 3D patches of 128\u00d7192\u00d7256 (spatial axes)\nimage.save(\"patch-non-iso.mla\")\n</code></pre> <p>When to use:</p> <ul> <li>your patch sampling is strongly anisotropic (common with anisotropic spacing),</li> <li>you have a fixed patch size in your training config and want to match it.</li> </ul>"},{"location":"optimization/#3-memory-mapped-patch-reads-training-style-access","title":"3) Memory-mapped patch reads (training-style access)","text":"<p>For large files, you typically want mmap reads so random patches don\u2019t require loading the entire array into RAM.</p> <pre><code>from mlarray import MLArray\n\n# read-only mmap: fast random access without loading the full volume\nimage = MLArray.open(\"patch-non-iso.mla\", mmap_mode='r')\n\npatch = image[10:20, 50:60]  # Read a crop/patch (partial read)\n</code></pre> <p>When to use:</p> <ul> <li>dataset is too large to fit in RAM,</li> <li>you do random access reads (patch sampling, interactive slicing).</li> </ul>"},{"location":"optimization/#4-memory-mapped-in-place-modification-advanced","title":"4) Memory-mapped in-place modification (advanced)","text":"<p>You can modify regions in-place with <code>mmap_mode='r+'</code>. This is useful for workflows like:</p> <ul> <li>writing derived arrays (e.g., post-processing outputs),</li> <li>patch-wise updates,</li> <li>annotation edits (careful with concurrency).</li> </ul> <pre><code>from mlarray import MLArray\n\nimage = MLArray.open(\"patch-non-iso.mla\", mmap_mode='r+')\nimage[10:20, 50:60] *= 5  # Modify crop in memory and on disk\nimage.close()\n</code></pre>"},{"location":"optimization/#5-create-a-new-memory-mapped-file-streaming-write","title":"5) Create a new memory-mapped file (streaming write)","text":"<p>If you want to create a file on disk and then fill it (without holding the full array in memory), use <code>create(..., shape=..., dtype=..., mmap_mode='w+')</code>. MLArray will compute and store the optimized layout up front.</p> <pre><code>import numpy as np\nfrom mlarray import MLArray\n\nshape = (128, 256, 256)\ndtype = np.float32\n\nimage = MLArray.create(\n    \"streamed-write.mla\",\n    shape=shape,\n    dtype=dtype,\n    mmap_mode='w+',\n    patch_size=192,  # optimize for your training patch size\n)\n\n# Fill incrementally if you want (here we write everything at once)\nimage[...] = np.random.random(shape).astype(dtype)\nimage.close()\n</code></pre> <p>When to use:</p> <ul> <li>you generate data on the fly,</li> <li>you want to avoid a full in-memory intermediate array.</li> </ul>"},{"location":"optimization/#6-manual-chunkblock-sizing-experts-only","title":"6) Manual chunk/block sizing (experts only)","text":"<p>If you already know what you\u2019re doing (or want to reproduce a very specific layout), you can override the automatic optimization. Note that in MLArray, <code>patch_size</code> and <code>chunk_size</code>/<code>block_size</code> are mutually exclusive.</p> <pre><code>from mlarray import MLArray\n\nloaded = MLArray(\"sample.mla\")\nimage = MLArray(\n    loaded.to_numpy(),\n    patch_size=None,\n    chunk_size=(1, 128, 128),\n    block_size=(1, 32, 32),\n)\nimage.save(\"manual-layout.mla\")\n</code></pre> <p>When to use:</p> <ul> <li>you benchmarked and found a better layout for your hardware/access pattern,</li> <li>you need strict reproducibility across environments.</li> </ul>"},{"location":"optimization/#7-let-blosc2-auto-configure-chunkblock-sizes","title":"7) Let Blosc2 auto-configure chunk/block sizes","text":"<p>If you set <code>patch_size=None</code> (and don\u2019t provide chunk/block sizes), Blosc2 will choose chunk/block sizes itself. This can be useful for experimentation or as a baseline.</p> <pre><code>from mlarray import MLArray\n\nloaded = MLArray(\"sample.mla\")\nimage = MLArray(loaded.to_numpy(), patch_size=None)\n\n# If patch_size, chunk_size and block_size are all None, Blosc2 auto-configures\nimage.save(\"blosc2-auto.mla\")\n</code></pre> <p>When to use:</p> <ul> <li>you want to compare MLArray\u2019s patch optimization against Blosc2 defaults,</li> <li>you don\u2019t have a meaningful patch size (non-ML access patterns).</li> </ul>"},{"location":"optimization/#notes-and-practical-tips","title":"Notes and practical tips","text":"<ul> <li>Patch optimization is currently implemented for 2D and 3D images (with at most one further non-spatial axis). If your data falls outside that, you can still set <code>chunk_size</code>/<code>block_size</code> manually or let Blosc2 decide.</li> <li>The best patch size to use is usually the patch size your dataloader requests most often (training patch, not necessarily inference tile size).</li> <li>If you\u2019re unsure: start with the default (<code>patch_size='default'</code>) and only tune if profiling shows I/O bottlenecks.</li> </ul>"},{"location":"schema/","title":"MLArray Metadata Schema","text":"<p>This section defines the MLArray metadata schema: the standardized structure used to store and retrieve metadata alongside array data.</p> <p>The schema is designed around a few core goals:</p> <ul> <li>Interoperability: tools can reliably access common fields (e.g., spacing, orientation, statistics) without guessing conventions.</li> <li>Flexibility: users can still store arbitrary metadata (including raw metadata from existing formats) without being forced into a rigid structure.</li> <li>Format preservation: MLArray can act as a storage and ML-optimized alternative to existing image formats (e.g., DICOM, NIfTI, NRRD) while retaining their metadata in a consistent place.</li> <li>Practicality for ML workflows: fields like <code>is_seg</code>, <code>bbox</code>, and <code>blosc2</code> directly support common training, preprocessing, and patch-based access patterns.</li> </ul> <p>All fields in the schema are JSON-serializable unless otherwise noted. Fields marked as <code>Optional[...]</code> may be omitted if unknown or not applicable.</p>"},{"location":"schema/#representation-notes","title":"Representation notes","text":"<p>Many namespaces are implemented as single-key dataclasses (subclasses of <code>SingleKeyBaseMeta</code>). In Python, these behave like their wrapped value (e.g., <code>meta.is_seg</code> is a <code>bool</code>, <code>meta.source</code> is a <code>dict</code>). When serialized via <code>Meta.to_mapping()</code>, they appear as a one-field object keyed by their internal field name (e.g., <code>is_seg: {\"is_seg\": true}</code> or <code>source: {\"data\": {...}}</code>). <code>Meta.from_mapping()</code> accepts either the one-field object or the raw value and will coerce it to the correct class.</p>"},{"location":"schema/#meta","title":"Meta","text":"<p>Top-level metadata container.</p>"},{"location":"schema/#overview","title":"Overview","text":"<p><code>Meta</code> is the root object that groups all metadata into well-defined namespaces. Some namespaces are standardized (e.g., <code>spatial</code>, <code>stats</code>), while others are intentionally free-form (<code>source</code>, <code>extra</code>) to support arbitrary metadata and long-term extensibility. Several entries are single-key dataclasses that wrap a primitive value while still allowing schema-aware validation.</p>"},{"location":"schema/#source","title":"source","text":"<ul> <li>Description: Arbitrary JSON-serializable dictionary for metadata from the original image source.   Stores information from image sources such as DICOM, NIfTI, NRRD,   or other imaging formats.</li> <li>Dataclass: <code>MetaSource</code> (single-key wrapper).</li> </ul> field type description data Dict[str, Any] JSON-serializable metadata from the source."},{"location":"schema/#extra","title":"extra","text":"<ul> <li>Description: Flexible container for arbitrary, JSON-serializable metadata   when no schema exists. Intended for experimental or application-specific   fields that are not part of the standard.</li> <li>Dataclass: <code>MetaExtra</code> (single-key wrapper).</li> </ul> field type description data Dict[str, Any] JSON-serializable metadata for extra fields."},{"location":"schema/#spatial","title":"spatial","text":"<ul> <li>Description: Spatial metadata for the image.</li> <li>Dataclass: <code>MetaSpatial</code>.</li> </ul> <p>This section stores the information needed to interpret the array in physical space (e.g., voxel spacing, coordinate origin, and orientation). It also optionally captures array shape and axes layout to make downstream consumers more robust.</p> field type description spacing Optional[List[float]] Voxel spacing per spatial axis, length = <code>ndims</code>. origin Optional[List[float]] Origin per spatial axis, length = <code>ndims</code>. direction Optional[List[List[float]]] Direction matrix, shape <code>[ndims][ndims]</code>. shape Optional[List[int]] Full array shape, length = spatial + non-spatial axes. axis_labels Optional[List[str,AxisLabel]] Per-axis labels or roles, length = full array <code>ndims</code>. axis_units Optional[List[str]] Per-axis units, length = full array <code>ndims</code>."},{"location":"schema/#axislabel","title":"AxisLabel","text":"<p>Axis labels describe the semantic role of each axis. They may be provided as strings or enum values.</p> value description spatial Generic spatial axis (used when no axis-specific label). spatial_x Spatial axis representing X. spatial_y Spatial axis representing Y. spatial_z Spatial axis representing Z. non_spatial Generic non-spatial axis. channel Channel axis (e.g., color channels or feature maps). temporal Time axis. continuous Continuous-valued axis (non-spatial). components Component axis (e.g., vector components)."},{"location":"schema/#stats","title":"stats","text":"<ul> <li>Description: Summary statistics for the image.</li> <li>Dataclass: <code>MetaStatistics</code>.</li> </ul> <p>This section stores precomputed global statistics for the array, which can be useful for normalization, QA, dataset inspection, and visualization defaults.</p> field type description min Optional[float] Minimum value. max Optional[float] Maximum value. mean Optional[float] Mean value. median Optional[float] Median value. std Optional[float] Standard deviation. percentile_min Optional[float] Minimum within a selected percentile range. percentile_max Optional[float] Maximum within a selected percentile range. percentile_mean Optional[float] Mean within a selected percentile range. percentile_median Optional[float] Median within a selected percentile range. percentile_std Optional[float] Standard deviation within a selected percentile range. percentile_min_key Optional[float] Minimum percentile key used to determine percentile_min (for example 0.05). percentile_max_key Optional[float] Maximum percentile key used to determine percentile_max (for example 0.95)."},{"location":"schema/#bbox","title":"bbox","text":"<ul> <li>Description: Bounding boxes for objects/regions in the image.</li> <li>Dataclass: <code>MetaBbox</code>.</li> <li>Structure: List of bboxes, each bbox is a list with length equal to image <code>ndims</code>,   and each entry is <code>[min, max]</code>.</li> </ul> <p>Bounding boxes are stored in a normalized, axis-aligned representation that works across dimensionalities (2D, 3D, \u2026). This is especially useful for detection-style workflows, ROI cropping, dataset summaries, and interactive visualization.</p> field type description bboxes Optional[List[List[List[Union[int, float]]]]] Bounding boxes shaped <code>[num_bboxes][ndims][2]</code> (min/max), ints or floats. scores Optional[List[Union[int, float]]] Optional confidence scores aligned with <code>bboxes</code>. labels Optional[List[Union[str, int, float]]] Optional labels aligned with <code>bboxes</code>."},{"location":"schema/#is_seg","title":"is_seg","text":"<ul> <li>Description: Whether the image is a segmentation mask.</li> <li>Dataclass: <code>MetaIsSeg</code> (single-key wrapper).</li> </ul> field type description is_seg Optional[bool] True/False when known, None when unknown."},{"location":"schema/#blosc2","title":"blosc2","text":"<ul> <li>Description: Blosc2 layout parameters.</li> <li>Dataclass: <code>MetaBlosc2</code>.</li> </ul> <p>This section records how the array was laid out on disk (chunking, blocking, patching). It is primarily intended for reproducibility, debugging, and performance introspection.</p> field type description chunk_size Optional[List[float]] Chunk size per axis, length = full array <code>ndims</code> (including non-spatial axes). block_size Optional[List[float]] Block size per axis, length = full array <code>ndims</code> (including non-spatial axes). patch_size Optional[List[float]] Patch size per spatial axis, length = <code>ndims</code> (non-spatial axes excluded)."},{"location":"schema/#_has_array","title":"_has_array","text":"<ul> <li>Description: Whether this metadata instance represents an on-disk array.</li> <li>Dataclass: <code>MetaHasArray</code> (single-key wrapper).</li> </ul> field type description has_array bool True when an array payload is stored."},{"location":"schema/#_image_meta_format","title":"_image_meta_format","text":"<ul> <li>Description: Source format identifier for the <code>image</code> metadata (e.g., \"dicom\",   \"nifti\", \"nrrd\"). This is advisory and application-defined.</li> <li>Dataclass: <code>MetaImageFormat</code> (single-key wrapper).</li> </ul> field type description image_meta_format Optional[str] Identifier for the source metadata format."},{"location":"schema/#_mlarray_version","title":"_mlarray_version","text":"<ul> <li>Description: MLArray version string used to write the file.</li> <li>Dataclass: <code>MetaVersion</code> (single-key wrapper).</li> </ul> field type description mlarray_version Optional[str] Version string for the writer."},{"location":"usage/","title":"Usage","text":"<p>This section shows common usage patterns for creating, saving, and loading MLArray files, as well as working with memory mapping and metadata.</p> <p>MLArray is designed to feel natural in Python workflows: you can construct an <code>MLArray</code> directly from a NumPy array, save it to disk, and later load it again with a single line. For large images, MLArray also supports memory-mapped access, allowing you to read and modify only small regions of an image without loading the full array into RAM. In addition, MLArray exposes a consistent metadata interface, so you can store and retrieve both standardized metadata (e.g., spacing, origin) and arbitrary custom metadata (e.g., raw DICOM tags, experiment info).</p> <p>Below are practical examples that cover the most common workflows.</p>"},{"location":"usage/#default-usage","title":"Default usage","text":"<p>The simplest workflow: create an <code>MLArray</code> from a NumPy array, save it to disk, and load it back later.</p> <pre><code>import numpy as np\nfrom mlarray import MLArray\n\narray = np.random.random((128, 256, 256))\nimage = MLArray(array)  # Create MLArray image\nimage.save(\"sample.mla\")\n\nimage = MLArray(\"sample.mla\")  # Loads image\n</code></pre>"},{"location":"usage/#memory-mapped-usage","title":"Memory-mapped usage","text":"<p>Memory mapping allows you to access large arrays on disk without loading everything into memory. This is ideal for patch-based training, interactive visualization, or working with multi-GB/ TB-scale volumes.</p> <pre><code>from mlarray import MLArray\nimport numpy as np\n\n# read-only, partial access (default)\nimage = MLArray.open(\"sample.mla\", mmap_mode='r')  \ncrop = image[10:20, 50:60]  # Read crop\n\n# read/write, partial access\nimage = MLArray.open(\"sample.mla\", mmap_mode='r+')  \nimage[10:20, 50:60] *= 5  # Modify crop in memory and disk\n\n# read/write, partial access, create/overwrite\narray = np.random.random((128, 256, 256))\nimage = MLArray.create(\"sample.mla\", shape=array.shape, dtype=array.dtype, mmap_mode='w+')\nimage[...] = array  # Modify image in memory and disk\n</code></pre>"},{"location":"usage/#metadata-inspection-and-manipulation","title":"Metadata inspection and manipulation","text":"<p>MLArray provides first-class support for common image metadata (spacing, origin, direction), and also lets you attach arbitrary metadata from the source image source via <code>meta=...</code> (e.g., raw DICOM fields, acquisition parameters, dataset identifiers).</p> <pre><code>import numpy as np\nfrom mlarray import MLArray\n\narray = np.random.random((64, 128, 128))\nimage = MLArray(\n    array,\n    spacing=(1.0, 1.0, 1.5),\n    origin=(10.0, 10.0, 30.0),\n    direction=[[1, 0, 0], [0, 1, 0], [0, 0, 1]],\n    meta={\"patient_id\": \"123\", \"modality\": \"CT\"},  # Any metadata from the original image source (for example raw DICOM metadata)\n)\n\nprint(image.spacing)  # [1.0, 1.0, 1.5]\nprint(image.origin)  # [10.0, 10.0, 30.0]\nprint(image.meta.source)  # {\"patient_id\": \"123\", \"modality\": \"CT\"}\n\nimage.spacing[1] = 5.3\nimage.meta.source[\"study_id\"] = \"study-001\"\nimage.save(\"with-metadata.mla\")\n\n# Open memory-mapped\nimage = MLArray.open(\"with-metadata.mla\", mmap_mode='r+')  \nimage.meta.source[\"study_id\"] = \"new-study\"  # Modify metadata\nimage.close()  # Close and save metadata, only necessary to save modified metadata\n</code></pre>"},{"location":"usage/#copy-metadata-with-overrides","title":"Copy metadata with overrides","text":"<p>This pattern is useful when you want to generate derived data (e.g., predictions, augmentations, resampled images) while keeping most metadata consistent with a reference image, but selectively overriding specific fields like spacing.</p> <pre><code>import numpy as np\nfrom mlarray import MLArray\n\nbase = MLArray(\"sample.mla\")\narray = np.random.random(base.shape)\n\nimage = MLArray(\n    array,\n    spacing=(0.8, 0.8, 1.0),\n    copy=base,  # Copies all non-explicitly set arguments from base\n)\n\nimage.save(\"copied-metadata.mla\")\n</code></pre>"},{"location":"usage/#standardized-metadata-usage","title":"Standardized metadata usage","text":"<p>For structured workflows, MLArray supports a standardized metadata container via <code>Meta</code>. This makes metadata access explicit and predictable, while still allowing flexible extensions when needed.</p> <pre><code>import numpy as np\nfrom mlarray import MLArray, Meta\n\narray = np.random.random((64, 128, 128))\nimage = MLArray(\n    array,\n    meta=Meta(source={\"patient_id\": \"123\", \"modality\": \"CT\"}, is_seg=True),  # Add metadata in a pre-defined format\n)\n\nprint(image.meta.source)  # {\"patient_id\": \"123\", \"modality\": \"CT\"}\nprint(image.meta.is_seg)  # True\n\nimage.meta.source[\"study_id\"] = \"study-001\"\nimage.meta.is_seg = False\nimage.save(\"with-metadata.mla\")\n</code></pre>"},{"location":"usage/#non-spatial-data-usage","title":"Non-spatial data usage","text":"<p>Use <code>axis_labels</code> to mark which axes are spatial and which are non-spatial (channels, temporal, components, etc.). Spatial metadata (<code>spacing</code>, <code>origin</code>, <code>direction</code>) is specified only for the spatial axes, while the full array shape includes both spatial and non-spatial axes.</p> <pre><code>import numpy as np\nfrom mlarray import MLArray, MetaSpatial\n\n# Example shape: (time, z, y, x, channels)\narray = np.random.random((2, 6, 4, 4, 3, 2))\n\naxis_labels = [\n    MetaSpatial.AxisLabel.temporal,\n    MetaSpatial.AxisLabel.spatial_z,\n    MetaSpatial.AxisLabel.spatial_y,\n    \"spatial_x\",  # Possible to pass predefined labels as strings as well\n    MetaSpatial.AxisLabel.channel,\n    \"some-other-type\"  # Possible to pass arbitrary strings as well\n]\n\nimage = MLArray(\n    array,\n    spacing=(2.5, 0.7, 0.7),  # spatial axes only (z, y, x)\n    origin=(0.0, 0.0, 0.0),\n    axis_labels=axis_labels,\n    patch_size=None,\n)\n\n# Optional per-axis units (length = full array ndims)\nimage.meta.spatial.axis_units = [\"s\", \"mm\", \"mm\", \"mm\", \"\"]\nimage.save(\"time-series.mla\")\n</code></pre>"},{"location":"usage/#patch-size-variants","title":"Patch size variants","text":"<p>MLArray stores arrays in a chunked layout to enable efficient partial reads. You can control how data is chunked using <code>patch_size</code> (recommended in most cases), or manually specify chunk and block sizes when you need full control.</p>"},{"location":"usage/#default-patch-size-192","title":"Default patch size (192)","text":"<p>Uses the default patch configuration, optimized for typical ML patch-based access patterns.</p> <pre><code>from mlarray import MLArray\n\nimage = MLArray(\"sample.mla\")\nimage.save(\"default-patch.mla\")  # Keeps existing layout metadata\n\nloaded = MLArray(\"sample.mla\")\nimage = MLArray(loaded.to_numpy(), patch_size='default')\nimage.save(\"default-patch-relayout.mla\")  # Uses constructor patch_size='default' (192)\n</code></pre>"},{"location":"usage/#custom-isotropic-patch-size-512","title":"Custom isotropic patch size (512)","text":"<p>A larger patch size can improve throughput when you typically load large regions at once (at the cost of slightly less granular random access).</p> <pre><code>from mlarray import MLArray\n\nloaded = MLArray(\"sample.mla\")\nimage = MLArray(loaded.to_numpy(), patch_size=512)\nimage.save(\"patch-512.mla\")\n</code></pre>"},{"location":"usage/#custom-non-isotropic-patch-size","title":"Custom non-isotropic patch size","text":"<p>Non-isotropic patches are useful when one axis behaves differently (e.g., fewer slices in Z, anisotropic voxel spacing, or slice-wise training).</p> <pre><code>from mlarray import MLArray\n\nloaded = MLArray(\"sample.mla\")\nimage = MLArray(loaded.to_numpy(), patch_size=(128, 192, 256))\nimage.save(\"patch-non-iso.mla\")\n</code></pre>"},{"location":"usage/#manual-chunkblock-size","title":"Manual chunk/block size","text":"<p>For advanced use cases, you can explicitly define the chunk and block size used by the storage backend.</p> <pre><code>from mlarray import MLArray\n\nloaded = MLArray(\"sample.mla\")\nimage = MLArray(\n    loaded.to_numpy(),\n    patch_size=None,\n    chunk_size=(1, 128, 128),\n    block_size=(1, 32, 32),\n)\nimage.save(\"manual-chunk-block.mla\")\n</code></pre>"},{"location":"usage/#let-blosc2-itself-configure-chunkblock-size","title":"Let Blosc2 itself configure chunk/block size","text":"<p>If you disable MLArray patch sizing, Blosc2 can choose chunk and block sizes automatically. This can be helpful when experimenting or when you want to rely entirely on backend heuristics.</p> <pre><code>from mlarray import MLArray\n\nloaded = MLArray(\"sample.mla\")\nimage = MLArray(loaded.to_numpy(), patch_size=None)\n# If patch_size, chunk_size and block_size are all None, Blosc2 will auto-configure chunk and block size\nimage.save(\"blosc2-auto.mla\")\n</code></pre>"},{"location":"why/","title":"Why MLArray?","text":"<p>MLArray addresses a gap I repeatedly ran into over the last few years: we have excellent storage formats optimized for machine learning workloads, but no widely usable image format that combines efficient array storage with standardized, software-friendly metadata.</p> <p>Projects like Zarr and Blosc2 already solve the \u201cstore large arrays efficiently\u201d problem extremely well. However, they do not provide a standardized metadata layer for imaging. As a result, it\u2019s difficult to integrate their file formats into common analysis and visualization tools in a meaningful and consistent way.</p> <p>MLArray is designed to bridge that gap: a machine-learning-friendly array format that preserves metadata and enables a broader ecosystem of tooling around it.</p>"},{"location":"why/#how-does-mlarray-address-this-gap","title":"How does MLArray address this gap?","text":"<ul> <li> <p>A standardized, extensible metadata schema   MLArray defines a metadata schema that balances standardization and flexibility: software that supports MLArray has a consistent way to access relevant metadata, while users can still attach arbitrary custom metadata when needed.</p> </li> <li> <p>Preserve source metadata across conversions   Users can convert images from arbitrary formats to MLArray while preserving the source metadata in a structured and reproducible way. Tools that integrate MLArray can still access metadata according to the source format\u2019s conventions, which makes MLArray a practical alternative for ML pipelines without breaking downstream analysis or visualization workflows.</p> </li> <li> <p>Machine learning\u2013specific metadata support   In addition to format-preserving metadata, MLArray includes a dedicated schema for machine-learning-relevant information, and it also supports storing dynamic metadata outside predefined schemas.</p> </li> </ul>"},{"location":"why/#what-type-of-images-can-i-store-as-mlarray","title":"What type of images can I store as MLArray?","text":"<p>In short: any array data.</p> <p>MLArray was designed with very large N-dimensional images in mind, including:</p> <ul> <li>medical imaging (radiology, histopathology, etc.)</li> <li>satellite and remote sensing data</li> <li>general scientific imaging</li> <li>segmentation masks and label maps</li> </ul> <p>Natural image data can also be stored in MLArray, but it is often unnecessary\u2014formats like JPEG and PNG are already a strong default for many ML training pipelines.</p> <p>MLArray can also store metadata-only or non-array data, such as:</p> <ul> <li>bounding boxes</li> <li>regression targets</li> <li>classification results</li> </ul> <p>This can be useful when you want a standardized interface for accessing these annotations and results, enabling simpler analysis and visualization in software that supports MLArray.</p>"},{"location":"why/#how-is-mlarray-optimized-for-machine-learning-deep-learning","title":"How is MLArray optimized for Machine Learning / Deep Learning?","text":"<p>MLArray uses Blosc2 as its storage backend, which provides several properties that are particularly well-suited for machine learning and deep learning workloads.</p> <p>For details, see: ML Optimization</p>"}]}